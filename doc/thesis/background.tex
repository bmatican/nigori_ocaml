\chapter{Background and Motivations} \label{chapter:background}
The key insight for achieving good protocol design is understanding the two most crucial themes that should underpin the development process: \textit{simplicity} and \textit{modularity} \cite{ProtocolDesign}.

Simplicity refers to the idea that a well design protocol will often be made up of smaller pieces. In order to properly understand the working of the protocol, at large, it should suffice to understand the individual pieces, in isolation, together with the respective interactions between them. Moreover, these pieces should be specialized; they should have one clear functionality, which should potentially be easy to verify and guarantee.

Modularity, on the other hand, is supposed to complement simplicity. The concept implies that, in building a complex feature, it should require multiple smaller individual pieces. However, these should function as black boxes, assuming a well specified input and output: perfectly fine in isolation, to the extent that they can be both developed, maintained or replaced, accordingly, without affecting the integrity of the whole.

Overall, this section will highlight how the above two points, and other ideas on good protocol design, shaped the motivation and choices of this thesis.

\section{Choice of Protocol: Nigori}
As previously mentioned, in light of the objectives for this thesis, we decided to analyze the Nigori protocol.
The project was initially started at Google, with a draft specification by Ben Laurie in 2010 \cite{NigoriDraft}.
It proposed a protocol, and an implicit system revolving around it, that would allow users to login to a server and use it for data storage, while encrypting the content such that the server would be unaware of what the data actually represented.
The timeline of the project later involved Alastair Beresford (TODO: maybe reference time at Google?) creating an initial proof--of--concept implementation in python and a follow--up migration to Java.
An RFC \cite{NigoriRFC} of the protocol specification was also in the works in the meantime.
The Java version of the implementation was eventually brought to an almost complete point.
Also, in parallel with this thesis, a DART \cite{DART} / Javascript based version of the required client library for the protocol was being developed by Daniel Thomas.

As a protocol, Nigori was envisioned out of the increasingly prevalent use of the cloud as a storage platform and the direct impact that has on the privacy of both users and their respective data.
One the one hand, in such an environment, the cloud is one centralized entity for storing application specific data -- including potentially sensitive user data.
Nevertheless, the actual physical representation of the storage can be completely decentralized, to the extent of data lying in separate geographic regions.
This raises questions of the security and integrity of data, if the respective servers get compromised.

One the other hand, in parallel with the adoption of using cloud storage, the number of different types of clients accessing the respective data has also featured an increase in diversity.
As such, we now have different native mobile OS applications, various traditional (PC/laptop) operating systems and their native applications, as well as various browser counterparts, all serving as clients, potentially sending data back into the cloud.
In this context, being able to develop the core of a protocol once and have it compiled and used consistently and with strong guarantees across platforms, becomes a very strong incentive.
What is more, Nigori was created assuming the diversity of clients, both generically, and particularly, with each individual user potentially having different devices, running the same applications, that would require both proper synchronization mechanisms and strong data privacy guarantees.

Thus, given both the volatility of the project development, coupled with the multi--platform requirements, Nigori was a perfect candidate for an implementation based off of a continuous development specification.
In the following, we shall give a more detailed description of both the client and the server.

\subsection{Client}
By using Nigori, applications must be aware of two major components: the local client library and the (potentially) remote server.
The client is actively responsible with properly encrypting the user data and ensuring communication with the server is done appropriately.
However, on top of this, the client must also passively make use of distributed version control primitives (TODO: git, papers?) in order to guarantee that content is properly synchronized across a user's different devices and potential conflicts are mitigated -- through the \textit{App defined merge} step in Figure \ref{fig:sync}.

\myfig{Synchronization and separation of trust in Nigori.}{sync}{0.8}

As such, the protocol becomes highly client--centric, placing the responsibility of both security and conflict resolution on the user end.
Nevertheless, this is meant to increase the overall safety of the user's data, as, removing control from the server, implicitly places control in the hands of the user (client).
With this need for control comes an inherent set of responsibilities, however.
The client is thus focused highly on security, and as such, must make proper use of certain primitives, as described further -- and given in detail in the specification.
\begin{description}
  \item[\myref{SHA-1}] is a secure hash function that generates a 160--bit message digest, as specified in RFC3174 \cite{RFC3174}.
  It is used in Nigori either internally, in other primitives, or directly, to shorten long messages to a fixed size format, with small probability of collisions.

  \item[\myref{HMAC}] represents the hash--based message authentication code (MAC) of a message, under a certain key, as specified in RFC2104 \cite{RFC2104}.
  As with any MAC, it is used to verify both the integrity, as well as the authenticity of a certain message.
  Implicitly, \myref{SHA-1} is the hash function used.

  \item[\myref{DSA}] represents the Digital Signature Algorithm, as specified by the FIPS186 document \cite{DSA}.
  The algorithm generates a pair of public and private keys.
  These are used afterwards to sign a message on the client and verify the respective signature (and thus, message authenticity) on the server.
  The Nigori specification defines fixed parameters for obtaining a public key of size 3072 bits and a private key of 128 bits.

  \item[\myref{AES}] is a symmetric--key encryption algorithm, as specified by the FIPS197 document \cite{AES}.
  By its nature, it allows the same cryptographic key to be used for both encryption and decryption.
  As such, the client is able to encrypt its data before sending it to the server and decrypt it when getting it back.

  \item[\myref{PBKDF}] is the password based key derivation function, as specified in its respective RFC2898 \cite{RFC2898}, under \myref{PBKDF2}.
  This takes an input password, adds a salt, and applies a secure hash function, such as \myref{SHA-1} repeatedly, in order to generate values which are to later be used as cryptographic keys.
  A high number of iterations (over 1000) is to be used, to make it computationally intensive, and thus a difficult attack vector.
\end{description}

\begin{comment}
\begin{description}
  \item[\myref{SHA-1(M)}] is a secure hash function that generates a 160--bit message digest, as specified in RFC3174 \cite{RFC3174}, applied to message \myref{M}.
  \item[\myref{HMAC(K, M)}] represents the hash--based message authentication code of message \myref{M}, using key \myref{K}, as specified in RFC2104 \cite{RFC2104}.
  \item[\myref{PBKDF(PRF, P, S, C, dkLen)}] is the password based key derivation function, as specified in its respective RFC2898 \cite{RFC2898}, under \myref{PBKDF2}.
  Here, \myref{PRF} represents a pseudo--random function -- \myref{SHA-1} for Nigori's case --, \myref{P} represents the given password, \myref{S} the salt, \myref{C} the number of iterations and \myref{dkLen}, the expected output length.
  \item[\myref{DSA}] represents the Digital Signature Algorithm, as specified by the FIPS186 document \cite{DSA}.
  For Nigori, we require generating the public and private key pairs, signing message content and verifying signatures afterwards.
  The specification defines fixed parameters for obtaining a public key of size 3072 bits and a private key of 128 bits.
\end{description}
\end{comment}

Stemming from the security motivation comes another focus point for Nigori.
As a protocol, it aims to help users by giving one centralized location for encrypted storage, with direct access through one single password -- a master password.
As such, the system allows, through the use of the \myref{PBKDF} primitive, for cryptographic keys to be derived from this master password.
There are four keys the protocol requires, as defined in the specification:
\begin{description}
  \item[\myref{kuser}] is used for authenticating the user on the server; it is used in such a way as to not allow potential dictionary attacks against the user's master password.
  \item[\myref{kenc}] is used for encrypting the user's secrets.
  \item[\myref{kmac}] is used for generating the MACs and implicitly authenticating the secrets.
  \item[\myref{kiv}] is used to deterministically generate an initialization vector given a plaintext, thus preventing common prefix attacks, when using deterministic encryption.
\end{description}

For generating these above keys, the Nigori specification describes two methods, depending on how the system is setup.
The first one is called unassisted key derivation and it only requires the user presenting his master password for authentication at the server.
This has the drawback, however, that if the user forgets this password, all his data is subsequently lost (not decryptable), as there is no password recovery mechanism.
The second method involves an indirection layer through a third party service that will use the user's password to derive the key that will ultimately be used for the actual authentication to the Nigori backend.
As such, identity management is left to the third party, while the respective key to be used for contacting the Nigori data store cannot be lost.

For the scope of this thesis, only the first method has been implemented.
Since the four keys required are derived using \myref{PBKDF}, several parameters are needed.
While the number of iterations and the length of the output key are fixed constants for each respective key and the password is the user's actual master password, the salt is specifically created.
It is generated by applying \myref{PBKDF} once again to a concatenation of the username and servername, as the password, with the remaining parameters as fixed known constants.
This is done to make the actual key derivation process both user and server dependent.

For actual data encryption, the same four previously mentioned keys are used, in combination with two extra primitives, denoted \myref{EncDet} and \myref{Enc}, which stand for deterministic and non--deterministic encryption of data, respectively.
The difference in determinism comes from the use of an initialization vector, that is either random, or predetermined (\myref{kiv}), in an internal call to \myref{AES}.
In order to understand where the determinism comes into play, we must first describe the data format used in Nigori.

Finally, upon obtaining the respective keys, the client is responsible with encrypting content on upload and decrypting on download.
However, before we detail the respective operations, we must first go over the actual data storage format available in Nigori.
This is crucial for both clients that want to store content as well as servers that (must) support the respective functionality.
In effect, for a user, Nigori acts as a generic two--level index--value store.
Every user's stored data is a mapping from indices to their respective revision history -- since, as mentioned, for conflict resolution, all data is versioned.
This history, in turn, is as well a mapping, from revision ID to the respective value.
As such, when a client uploads data, it is added under a certain index and, under that, a specific revision ID.

TODO: make and add figure

As such, since clients wish to have all of their content encrypted, this means both indices, revisions and the actual data must be secrets.
Since for query purposes, the client must be able to provide a respective index or revision, that encryption must be deterministic.
However, for the actual data, that encryption can be non--deterministic.
Hence, the last pieces of cryptographic functionality represent two pairs of encrypt--decrypt functions, one that is deterministic (\myref{EncDet}, \myref{DecDet}), the other that is not (\myref{Enc}, \myref{Dec}).
They function by making use of \myref{AES} to encrypt the content and \myref{HMAC} to guarantee validity of messages.
The difference in determinism comes in the use of either a fixed (\myref{kiv}) or random initialization vector for \myref{AES}.
All these three components are concatenated together, such that the server cannot use the pieces to decrypt the content, where as the client, being able to generate the needed keys, can always decrypt its content back, on retrieval from the server.

Overall, the client is properly designed following the aforementioned two principles.
The individual cryptographic primitives act as the main pieces of functionality.
These can be abstracted away and implemented separately and potentially even formally verified for correctness.
On top of these, Nigori modularly builds the key generation methods as well as the encryption and decryption mechanics for user data.

\subsection{Server}
In describing the server, we can easily parallel between the respective pieces of functionality it needs to provide and the five constituent parts of a protocol \cite{ProtocolDesign}:
\begin{description}
  \item[Service] What it provides.
  \item[Assumptions] The environment in which it runs.
  \item[Vocabulary] Messages used for communication.
  \item[Encoding] Format of each message.
  \item[Procedure] Rules for consistency between message exchanges.
\end{description}

With regards to \textbf{service}, the server is primarily responsible for two things: properly authenticating users and safely storing their respective data.
However, to provide any type of functionality, the server must expose an interface, to allow communication.
This is achieved through the shared use of a Representational State Transfer (REST) \cite{REST} style interface.
The main idea behind such an interface involves a clear separation between client and server implementations and functional requirements.
Moreover, it assumes that the communication can be completely stateless, without the server needing to keep any extra information, across requests.
Thus, every new request made by a client must be fully self--contained.
There are several other requirements, yet these are the primary ones that are of interest to our server, in the context of this thesis.

In this context, the REST interface represents the underlying \textbf{assumptions} that the protocol makes about the environment in which it operates.
As such, the server provides a set of endpoints (explicit URL paths, relative to the base host name), corresponding to the various pieces of functionality that it exposes to clients.
Each endpoint expects a certain format of information, in order to properly do the functionality it promises.
The required format is abstracted away and described in the Nigori specification through the use of the actual protobuf \cite{protobuf} package that is used in the Java implementation.
A direct one--to--one mapping is thus established between the available endpoints and the messages that represent the expected payload format.
Overall, the provided interface acts much like remote procedural calls, with each function (HTTP requests at a certain endpoint) expecting a certain format of parameters (the matching message).

The various messages allowed in Nigori are primarily derived from the functionality that the server is expected to offer.
Moreover, while all requests expect a certain message format, some also deliver responses back to the client, which in turn are also a message, in the aforementioned sense.
Together, these messages describe the \textbf{vocabulary} used by Nigori, as a protocol.
As functionality goes, the messages are split into two main categories, as follows:
\begin{description}
  \item[User management] Since each server can keep track of data for multiple users, these messages are used for registering and unregistering users, as well as generic authentication.
  \begin{description}
    \item[Authenticate] The message must contain a hash of the user's DSA public key (for identifying the source), the servername (for identifying the destination), a one--time nonce, made of a timestamp and a random (four) byte string (to be checked for duplication, against replay attacks) and finally, the DSA signature of the entire message (to guarantee overall integrity).
    \item[Register] The message should contain the public key the user wishes to be identified by and a token (default blank) to be used for any potential administrative rights the server may configure (such as space quotas, ACLs or otherwise).
    \item[Unregister] The message must contain just an actual authentication message.
    This way, the endpoint can properly validate the identity of the user requesting the command.
  \end{description}
  \item[User data] All commands that are related to the data of one specific user require authentication.
  This is achieved by embedding an authentication message inside whichever message is required.
  As such, though, the respective DSA signature must cover the entirety of the message, as to respect the integrity guarantees it is meant to offer.
  Overall these commands are of three types:
  \begin{description}
    \item[Put] The main method of uploading content to a server.
    Considering the data format, a client is required to provide an index, a revision and a value.
    \item[Delete] The only method of modifying content already on the server is by removing it.
    This may be done on an explicit basis, by providing both an index and a revision, or generically by providing the index alone, expecting to remove all the revision history underneath.
    \item[Get] For accessing the data, there are multiple types of getter methods provided by the server.
    For each of these expected getter messages, a corresponding message format for the response is expected by the client.
    These getters are basically of three types:
    \begin{description}
      \item[Indices] These return all indices available for a specific user's data.
      \item[Revisions] These return all available revision IDs under a specific index.
      \item[Data] These return the actual data under a specific index.
      It can either be the entirety of the revision history, or one specific instance, if the revision is provided.
    \end{description}
  \end{description}
\end{description}

TODO: add figure with data flow from client to server and back.

The aforementioned message formats also requires an extra set of notes.
At the moment, the specification requires all communication to be done across HTTPS, to ensure a secure channel.
Moreover, every request must be an HTTP POST request, with the payload (body) being the actual message.
However, in order to communicate, the client and server must both understand the data they exchange.
As such, this data must be serialized to a common format.
The Nigori specification strongly favors protobufs, yet mandates that servers must at least provide JSON (TODO: mb cite?).
What is more, since the data that is sent can be arbitrary byte strings, some form of encoding is also required.
For this, Nigori mandates that all of the actual payload pieces must be encoded using Base64.

Together with these final notes, the messages now have a fully specified format, thus offering the \textbf{encoding} requirements of a well defined protocol.
Lastly, the functionality rules for each provided endpoint represent the overall \textbf{procedure} side of a protocol.
Because our server uses a REST interface, the overall set of rules is not too complex, however, since each new request is stateless.
Thus, as presented in the above figure, any message exchange can only be initiated by the client and will only receive one response from the server -- which will only carry payload on requests for getting information.

\section{Choice of environment: Mirage and OCaml}
As previously mentioned, the research part of the thesis also involved working with relatively new technologies.
To that end, we decided to use Mirage as a supporting backend for Nigori.
This was interesting from the novelty perspective, as the system was well within an alpha stage of release.
Thus, most parts of the system were constantly under ongoing development throughout the work done in this thesis.
Hence, while this work was primarily focused on protocol analysis, a secondary objective was also a use case analysis for Mirage itself, and the ecosystem surrounding it.
On a different note, this choice was also motivated by many practical aspects.
Mirage was built to be a \textit{library operating system}.
What this means is that, the application being developed can be packaged together with all the underlying functionality required from the actual operating system into a single \textit{unikernel} that can be directly deployed on top of hypervisors, such as Xen, on top of cloud infrastructure VMs.
In turn, for Nigori, this means that we can target different platforms simply by building the application on top of Mirage.

TODO: maybe add more...?

On a different note, one important choice that was made from the beginning of the project was that all the implementation work should be done in a functional programming language with a static type system.
The motivations for this are two fold.
On the one hand, this opens up the protocol implementation, or at least crucial underlying pieces of it, to formal verification, which can directly vouchsafe certain protocol assumptions.
On the other hand, type systems directly provide the developer with a safety net, thus helping to ensure that the theoretical design of the protocol at hand is not involuntarily broken during implementation.
Thus, abstract specifications of data and interactions can be turned into concrete data types and functions acting explicitly on them, with the language itself helping to enforce these constraints.
Overall, this should help increase the overall security of the protocol, which, considering the ideology behind Nigori, was important.
Moreover, together with the aforementioned principles of simplicity and modularity, such a language helps put the problem of protocol design and implementation into a development funnel style picture.

TODO: add picture.

Thus, the base of the funnel consists of the many (small) individual pieces of protocol functionality, properly specified and potentially formally verified, guaranteed to offer the envisioned functionality, such as the cryptographic primitives in Nigori.
The top of the funnel is represented by the broad spectrum of final deployments of the protocol, depending on the targeted platform.
All of these would in a sense be variations, or specializations of the core of the protocol, the narrow waist of the funnel, which would be represent the complete implementation of the protocol, achieved by modularly combining the functionality from lower down the funnel, in our language of choice, ready to be compiled away towards the needed platforms.

Considering both the requirement for a functional programming for implementation, as well as the fact that Mirage is written in OCaml, this made the choice of language relatively straightforward, as it would greatly help with integration work, since all the libraries the system provides would become directly available for an application developer.
What is more, the development environment around Mirage consists of plenty of OCaml libraries adapted for direct use.
As such, we were able to leverage quite a great deal of functionality in engineering the Nigori implementation.
For HTTP communication, we leveraged the \myref{ocaml-cohttp} library's client and server, which could be directly used either in a UNIX environment, or in a Mirage microkernel.
With regards to the actual messages used in the communication, we used the \myref{atdgen} library, which allowed for \textit{Adjustable Type Definitions} to be written down and annotated, before processing and generating of corresponding OCaml types.
What is more, the library also provided primitives for serializing and deserializing these types to and from JSON.
Certain cryptographic building blocks were available using the OCaml \myref{cryptokit} library, which allowed for building all of the required primitives for Nigori.
For a storage, a backend Object Relational Mapping (ORM) is also available, by using the \myref{ocaml-orm} library.
This allows for carefully crafted OCaml types to be persisted using SQLite, almost seamless to the developer, while also allowing application specific OCaml code running directly on said types, without having to handle raw SQL.
Finally, through the use of the \myref{js\_of\_ocaml} library, we were able to also compile the OCaml client to Javascript, while functorizing the various pieces which were not directly available (such as the cryptography and HTTP client functionality) and replacing them with suitable Javascript library calls or implementations.
